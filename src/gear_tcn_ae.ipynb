{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gear-tcn-ae.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 使用 TCN-AE（時間卷積神經網路 ＋ 自動編碼器）進行齒輪振動 - 時序資料 - 的缺陷診斷"
      ],
      "metadata": {
        "id": "k1d8zCdeRKuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"colab-tcn-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/iinoshirozheng/TCN-AutoEncoder/blob/main/TCN_AutoEncoder.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />在 Google Colab 上面執行</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/iinoshirozheng/TCN-AutoEncoder/blob/main/TCN_AutoEncoder.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />在我的 GitHub 上查看源碼</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "Zv1PbeSKmmsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "請注意以下幾點：\n",
        "- 使用 Google CoLab 時，因為訓練時間較長，請記得啟動 GPU 加速：\n",
        "   - 到上方選單找到 編輯→筆記本設置\n",
        "   - 從硬件加速器下拉列表中選擇 GPU"
      ],
      "metadata": {
        "id": "F321jB0k7xZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# 首先檢查是否在 Google CoLab 上執行\n",
        "#\n",
        "IN_COLAB = 'google.colab' in str(get_ipython())\n",
        "if IN_COLAB:\n",
        "    print('Running on Google CoLab!')\n",
        "else:\n",
        "    print('Not running on Google CoLab!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHKVRbs77njr",
        "outputId": "d9f8aa0a-c991-4989-fbdd-513533707ad0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google CoLab!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# 下載必須要用的 packages 以及 repository\n",
        "#\n",
        "import os\n",
        "if IN_COLAB:\n",
        "    !pip3 install keras-tcn\n",
        "    if not os.path.exists('/content/gear-tcn-ae/'):\n",
        "        print(\"Repo not cloned yet. Do it now!\")\n",
        "        !git clone https://github.com/iinoshirozheng/gear-tcn-ae /content/gear-tcn-ae/\n",
        "    else:\n",
        "        print(\"Repository already cloned!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JPNK4Rz9WqB",
        "outputId": "56308825-fde3-46a0-b3d3-63e18b3341f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.4.2-py3-none-any.whl (13 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.43.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.10.0.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.7.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.24.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.3.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (13.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.13.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (1.1.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-tcn) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->keras-tcn) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->keras-tcn) (1.8.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-tcn) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-tcn) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->keras-tcn) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->keras-tcn) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->keras-tcn) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->keras-tcn) (3.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->keras-tcn) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, keras-tcn\n",
            "Successfully installed keras-tcn-3.4.2 tensorflow-addons-0.15.0\n",
            "Repo not cloned yet. Do it now!\n",
            "Cloning into '/content/gear-tcn-ae'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 13 (delta 0), reused 10 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# In Google CoLab: 更變資料夾到 gear-tcn-ae/src\n",
        "#\n",
        "if IN_COLAB and os.getcwd() != \"/content/gear-tcn-ae/src\":\n",
        "  # Print the current working directory\n",
        "  print(\"Old working directory: {0}\".format(os.getcwd()))\n",
        "\n",
        "  # Change the current working directory\n",
        "  os.chdir('/content/gear-tcn-ae/src')\n",
        "\n",
        "  # Print the current working directory\n",
        "  print(\"New working directory: {0}\".format(os.getcwd()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUoMIt_K_0pf",
        "outputId": "215fb99a-a1c6-472c-b227-cc7c121c1480"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old working directory: /content\n",
            "New working directory: /content/gear-tcn-ae/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# 如果這邊錯誤 ，代表 GPU 沒有開啟 ，請確認有將 GPU 開啟\n",
        "#\n",
        "if IN_COLAB:\n",
        "    %tensorflow_version 2.x\n",
        "    import tensorflow as tf\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        raise SystemError('GPU device not found -- please open the GPU')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "    !nvidia-smi"
      ],
      "metadata": {
        "id": "OJBgp5OwIvyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from tcn import TCN\n",
        "import time\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import UpSampling1D\n",
        "from tensorflow.keras.layers import AveragePooling1D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Y28_DlPvJoMK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utilities \n",
        "def roll_fast(a, window):\n",
        "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
        "    strides = a.strides + (a.strides[-1],)\n",
        "    return numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
        "\n",
        "def slide_window(df, window_length, verbose = 1):\n",
        "    # orig_TS_list = []\n",
        "    X_list = []\n",
        "    series = df.copy()\n",
        "    for i in series.columns.values: # loop through all input dimensions\n",
        "        s = series[i]\n",
        "        s2 = roll_fast(s.values, window_length)\n",
        "        X_list.append(s2)\n",
        "    X = numpy.dstack((X_list))\n",
        "    if verbose > 2:\n",
        "        print(\"X.shape:\", X.shape)\n",
        "    return X\n",
        "\n",
        "# Computes the squared Mahalanobis distance of each data point (row)\n",
        "# to the center of the distribution, described by cov and mu. \n",
        "# (or any other point mu).\n",
        "# If the parameters cov and mu are left empty, then this function \n",
        "# will compute them based on the data X.\n",
        "def mahalanobis_distance(X, cov=None, mu=None):\n",
        "    if mu is None:\n",
        "        mu = numpy.mean(X, axis=0)\n",
        "    if cov is None:\n",
        "        cov = numpy.cov(X, rowvar = False)\n",
        "    try:\n",
        "        inv_cov = numpy.linalg.inv(cov)\n",
        "    except numpy.linalg.LinAlgError as err:\n",
        "        print(\"Error, probably singular matrix!\")\n",
        "        inv_cov = numpy.eye(cov.shape[0])\n",
        "    \n",
        "    X_diff_mu = X - mu\n",
        "    M = numpy.apply_along_axis(lambda x: \n",
        "                    numpy.matmul(numpy.matmul(x, inv_cov), x.T) ,1 , X_diff_mu)\n",
        "    return M\n",
        "\n",
        "def get_anomaly_windows(is_anomaly):\n",
        "    # add a zero at the beginning and end of the sequence and look for the edges of the anomaly windows\n",
        "    edges = numpy.diff(numpy.concatenate([[0],is_anomaly,[0]])).nonzero()[0]\n",
        "    return edges.reshape((-1,2)) + numpy.array([0,-1])\n",
        "\n",
        "def plot_results(data, anomaly_score, plot_range = None, plot_signal = False, plot_anomaly_score = True):\n",
        "    #anomaly_score = results[\"anomaly_score\"]\n",
        "    series = data[1] \n",
        "    extend_window = 0\n",
        "    my_alpha = 0.15\n",
        "    cols = [\"value\"]\n",
        "    if plot_range is None:\n",
        "        plot_range = (0,series.shape[0])\n",
        "        extend_window = 10 # extend anomaly window, just to see something in the plot\n",
        "        my_alpha = 0.4\n",
        "    plt.figure(figsize=(25,8))\n",
        "    if plot_signal:\n",
        "        plt.plot(series[cols].values, zorder=1)\n",
        "        plt.ylim((series[cols].values.min(),series[cols].values.max()));\n",
        "    if plot_anomaly_score:\n",
        "        plt.plot(anomaly_score, 'b-', zorder=2)\n",
        "\n",
        "    real_anoms = get_anomaly_windows(anomaly_score>30)\n",
        "    \n",
        "    for i in real_anoms:\n",
        "        plt.axvspan(i[0]-extend_window,i[1]+extend_window, ymin=0.0, ymax=50, alpha=my_alpha, color='red')\n",
        "        \n",
        "    ignorable_win = get_anomaly_windows(anomaly_score<1)\n",
        "    for i in ignorable_win:\n",
        "        plt.axvspan(i[0],i[1], ymin=0.0, ymax=50, alpha=my_alpha, color='yellow')\n",
        "        \n",
        "    # Choose the threshold as the smallest possible value that would not produce a false positive\n",
        "    anoms = ((anomaly_score>30).all() | (anomaly_score<1).all())\n",
        "    extd = sorted(list(set(numpy.where(anoms)[0]) | set(numpy.where(anoms)[0] + 250) | set(numpy.where(anoms)[0] - 250)))\n",
        "    idx = numpy.array(extd)\n",
        "    idx = idx[(idx>=0) & (idx<anomaly_score.shape[0])]\n",
        "    ignore = (numpy.ones(anomaly_score.shape[0]) == 1)\n",
        "    ignore[idx] = False\n",
        "    artifical_threshold = anomaly_score[ignore].max()\n",
        "    if plot_anomaly_score:\n",
        "        plt.axhline(y=artifical_threshold, xmin=0.0, xmax=10240, color='r')\n",
        "\n",
        "    plt.xlim(plot_range);\n",
        "    plt.draw()"
      ],
      "metadata": {
        "id": "t0-zCnw0pYWH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TCNAE:\n",
        "    \"\"\"\n",
        "    A class used to represent the Temporal Convolutional Autoencoder (TCN-AE).\n",
        "\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    model : xxtypexx\n",
        "        The TCN-AE model.\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    build_model(verbose = 1)\n",
        "        Builds the model\n",
        "    \"\"\"\n",
        "    \n",
        "    model = None\n",
        "    \n",
        "    def __init__(self,\n",
        "                 ts_dimension = 1,\n",
        "                 dilations = (1, 2, 4, 8, 16),\n",
        "                 nb_filters = 20,\n",
        "                 kernel_size = 20,\n",
        "                 nb_stacks = 1,\n",
        "                 padding = 'same',\n",
        "                 dropout_rate = 0.00,\n",
        "                 filters_conv1d = 8,\n",
        "                 activation_conv1d = 'linear',\n",
        "                 latent_sample_rate = 42,\n",
        "                 pooler = AveragePooling1D,\n",
        "                 lr = 0.001,\n",
        "                 conv_kernel_init = 'glorot_normal',\n",
        "                 loss = 'logcosh',\n",
        "                 use_early_stopping = False,\n",
        "                 error_window_length = 128,\n",
        "                 verbose = 1\n",
        "                ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        ts_dimension : int\n",
        "            The dimension of the time series (default is 1)\n",
        "        dilations : tuple\n",
        "            The dilation rates used in the TCN-AE model (default is (1, 2, 4, 8, 16))\n",
        "        nb_filters : int\n",
        "            The number of filters used in the dilated convolutional layers. All dilated conv. layers use the same number of filters (default is 20)\n",
        "        \"\"\"\n",
        "        \n",
        "        self.ts_dimension = ts_dimension\n",
        "        self.dilations = dilations\n",
        "        self.nb_filters = nb_filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.nb_stacks = nb_stacks\n",
        "        self.padding = padding\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.filters_conv1d = filters_conv1d\n",
        "        self.activation_conv1d = activation_conv1d\n",
        "        self.latent_sample_rate = latent_sample_rate\n",
        "        self.pooler = pooler\n",
        "        self.lr = lr\n",
        "        self.conv_kernel_init = conv_kernel_init\n",
        "        self.loss = loss\n",
        "        self.use_early_stopping = use_early_stopping\n",
        "        self.error_window_length = error_window_length\n",
        "        \n",
        "        # build the model\n",
        "        self.build_model(verbose = verbose)\n",
        "        \n",
        "    \n",
        "    def build_model(self, verbose = 1):\n",
        "        \"\"\"Builds the TCN-AE model.\n",
        "\n",
        "        If the argument `verbose` isn't passed in, the default verbosity level is used.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        verbose : str, optional\n",
        "            The verbosity level (default is 1)\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        KerasXYZType\n",
        "        Todo\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        NotImplementedError\n",
        "            If ...\n",
        "        \"\"\"\n",
        "        \n",
        "        tensorflow.keras.backend.clear_session()\n",
        "        sampling_factor = self.latent_sample_rate\n",
        "        i = Input(batch_shape=(None, None, self.ts_dimension))\n",
        "\n",
        "        # Put signal through TCN. Output-shape: (batch,sequence length, nb_filters)\n",
        "        tcn_enc = TCN(nb_filters=self.nb_filters, kernel_size=self.kernel_size, nb_stacks=self.nb_stacks, dilations=self.dilations, \n",
        "                      padding=self.padding, use_skip_connections=True, dropout_rate=self.dropout_rate, return_sequences=True,\n",
        "                      kernel_initializer=self.conv_kernel_init,activation = tensorflow.nn.relu , name='tcn-enc')(i)\n",
        "\n",
        "        # Now, adjust the number of channels...\n",
        "        enc_flat = Conv1D(filters=self.filters_conv1d, kernel_size=1, activation=self.activation_conv1d, padding=self.padding)(tcn_enc)\n",
        "\n",
        "        ## Do some average (max) pooling to get a compressed representation of the time series (e.g. a sequence of length 8)\n",
        "        enc_pooled = self.pooler(pool_size=sampling_factor, strides=None, padding='valid', data_format='channels_last')(enc_flat)\n",
        "        \n",
        "        # If you want, maybe put the pooled values through a non-linear Activation\n",
        "        enc_out = Activation(\"linear\")(enc_pooled)\n",
        "\n",
        "        # Now we should have a short sequence, which we will upsample again and then try to reconstruct the original series\n",
        "        dec_upsample = UpSampling1D(size=sampling_factor)(enc_out)\n",
        "\n",
        "        dec_reconstructed = TCN(nb_filters=self.nb_filters, kernel_size=self.kernel_size, nb_stacks=self.nb_stacks, dilations=self.dilations, \n",
        "                                padding=self.padding, use_skip_connections=True, dropout_rate=self.dropout_rate, return_sequences=True,\n",
        "                                kernel_initializer=self.conv_kernel_init, name='tcn-dec')(dec_upsample)\n",
        "\n",
        "        # Put the filter-outputs through a dense layer finally, to get the reconstructed signal\n",
        "        o = Dense(self.ts_dimension, activation='linear')(dec_reconstructed)\n",
        "\n",
        "        model = Model(inputs=[i], outputs=[o])\n",
        "\n",
        "        adam = optimizers.Adam(lr=self.lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=True)\n",
        "        model.compile(loss=self.loss, optimizer=adam, metrics=[self.loss])\n",
        "        if verbose > 1:\n",
        "            model.summary()\n",
        "        self.model = model\n",
        "    \n",
        "    def fit(self, train_X, train_Y, batch_size=32, epochs=40, verbose = 1):\n",
        "        my_callbacks = None\n",
        "        if self.use_early_stopping:\n",
        "            my_callbacks = [EarlyStopping(monitor='val_loss', patience=2, min_delta=1e-4, restore_best_weights=True)]\n",
        "\n",
        "        keras_verbose = 0\n",
        "        if verbose > 0:\n",
        "            print(\"> Starting the Training...\")\n",
        "            keras_verbose = 2\n",
        "        start = time.time()\n",
        "        history = self.model.fit(train_X, train_Y, \n",
        "                            batch_size=batch_size, \n",
        "                            epochs=epochs, \n",
        "                            validation_split=0.001, \n",
        "                            shuffle=True,\n",
        "                            callbacks=my_callbacks,\n",
        "                            verbose=keras_verbose)\n",
        "        if verbose > 0:\n",
        "            print(\"> Training Time :\", round(time.time() - start), \"seconds.\")\n",
        "    \n",
        "    def predict(self, test_X):\n",
        "        X_rec =  self.model.predict(test_X)\n",
        "        \n",
        "        # do some padding in the end, since not necessarily the whole time series is reconstructed\n",
        "        X_rec = numpy.pad(X_rec, ((0,0),(0, test_X.shape[1] - X_rec.shape[1] ), (0,0)), 'constant') \n",
        "        E_rec = (X_rec - test_X).squeeze()\n",
        "        Err = slide_window(pandas.DataFrame(E_rec), self.error_window_length, verbose = 0)\n",
        "        Err = Err.reshape(-1, Err.shape[-1]*Err.shape[-2])\n",
        "        sel = numpy.random.choice(range(Err.shape[0]),int(Err.shape[0]*0.98))\n",
        "        mu = numpy.mean(Err[sel], axis=0)\n",
        "        cov = numpy.cov(Err[sel], rowvar = False)\n",
        "        sq_mahalanobis = mahalanobis_distance(X=Err[:], cov=cov, mu=mu)\n",
        "        # moving average over mahalanobis distance. Only slightly smooths the signal\n",
        "        anomaly_score = numpy.convolve(sq_mahalanobis, numpy.ones((50,))/50, mode='same')\n",
        "        anomaly_score = numpy.sqrt(anomaly_score)\n",
        "        return anomaly_score"
      ],
      "metadata": {
        "id": "eGmbsO0Xp7lF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##========================================\n",
        "##訓練集\n",
        "traindata = pandas.read_csv(\"train_data.csv\", encoding= 'unicode_escape')\n",
        "train_data = traindata.values[:,:3]\n",
        "train_X = numpy.reshape(train_data, (11, 10206, 3))\n",
        "##測試集\n",
        "testdata = pandas.read_csv(\"test_data.csv\", encoding= 'unicode_escape')\n",
        "test_data = testdata.values[:,:3]\n",
        "test_X = numpy.reshape(test_data, (1, 10206, 3))\n",
        "\n",
        "print(\"train_X.shape:\", train_X.shape)\n",
        "print(\"test_X.shape:\", test_X.shape)\n",
        "\n",
        "##========================================\n",
        "##Step1、build model\n",
        "##Step2、訓練模型\n",
        "tcn_ae = TCNAE(ts_dimension=3)\n",
        "tcn_ae.fit(train_X, train_X, batch_size=1, epochs=3, verbose=1)\n",
        "\n",
        "##========================================\n",
        "##用訓練好的模型測試\n",
        "anomaly_score = tcn_ae.predict(test_X)\n",
        "\n",
        "##========================================\n",
        "##繪出結果\n",
        "plot_results(test_data, anomaly_score, plot_range = None, plot_signal = False, plot_anomaly_score = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "zysAKi8IC1rS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}