{"cells":[{"cell_type":"code","execution_count":null,"outputs":[],"source":["import inspect\n","from typing import List\n","\n","from tensorflow.keras import backend as K, Model, Input, optimizers\n","# pylint: disable=E0611\n","from tensorflow.keras import layers\n","# pylint: disable=E0611\n","from tensorflow.keras.layers import Activation, SpatialDropout1D, Lambda\n","# pylint: disable=E0611\n","from tensorflow.keras.layers import Layer, Conv1D, Dense, BatchNormalization, LayerNormalization\n","import tensorflow\n","\n","class SE_Block(Layer):\n","    def __init__(self,reduction = 16,**kwargs):\n","        super(SE_Block,self).__init__(**kwargs)\n","        tensorflow.config.run_functions_eagerly(True)\n","        self.reduction = reduction\n","    def build(self, input_shape):\n","        pass\n","    @tensorflow.function\n","    def call(self, inputs):\n","        num_filters = inputs.shape[-1]\n","        squeeze = tensorflow.keras.layers.GlobalAveragePooling1D()(inputs)\n","\n","        excitation = tensorflow.keras.layers.Dense(units=num_filters/self.reduction)(squeeze)\n","        excitation = tensorflow.keras.layers.Activation('relu')(excitation)\n","        excitation = tensorflow.keras.layers.Dense(units=num_filters)(excitation)\n","        excitation = tensorflow.keras.layers.Activation('sigmoid')(excitation)\n","        excitation = tensorflow.keras.layers.Reshape([1, num_filters])(excitation)\n","\n","        scale = inputs * excitation\n","\n","        return scale\n","\n","\n","def is_power_of_two(num: int):\n","    return num != 0 and ((num & (num - 1)) == 0)\n","\n","\n","def adjust_dilations(dilations: list):\n","    if all([is_power_of_two(i) for i in dilations]):\n","        return dilations\n","    else:\n","        new_dilations = [2 ** i for i in dilations]\n","        return new_dilations\n","\n","\n","class ResidualBlock(Layer):\n","\n","    def __init__(self,\n","                 dilation_rate: int,\n","                 nb_filters: int,\n","                 kernel_size: int,\n","                 padding: str,\n","                 activation: str = 'relu',\n","                 dropout_rate: float = 0,\n","                 kernel_initializer: str = 'he_normal',\n","                 use_batch_norm: bool = False,\n","                 use_layer_norm: bool = False,\n","                 use_weight_norm: bool = False,\n","                 **kwargs):\n","        \"\"\"Defines the residual block for the WaveNet TCN\n","        Args:\n","            x: The previous layer in the model\n","            training: boolean indicating whether the layer should behave in training mode or in inference mode\n","            dilation_rate: The dilation power of 2 we are using for this residual block\n","            nb_filters: The number of convolutional filters to use in this block\n","            kernel_size: The size of the convolutional kernel\n","            padding: The padding used in the convolutional layers, 'same' or 'causal'.\n","            activation: The final activation used in o = Activation(x + F(x))\n","            dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n","            kernel_initializer: Initializer for the kernel weights matrix (Conv1D).\n","            use_batch_norm: Whether to use batch normalization in the residual layers or not.\n","            use_layer_norm: Whether to use layer normalization in the residual layers or not.\n","            use_weight_norm: Whether to use weight normalization in the residual layers or not.\n","            kwargs: Any initializers for Layer class.\n","        \"\"\"\n","\n","        self.dilation_rate = dilation_rate\n","        self.nb_filters = nb_filters\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.activation = activation\n","        self.dropout_rate = dropout_rate\n","        self.use_batch_norm = use_batch_norm\n","        self.use_layer_norm = use_layer_norm\n","        self.use_weight_norm = use_weight_norm\n","        self.kernel_initializer = kernel_initializer\n","        self.layers = []\n","        self.shape_match_conv = None\n","        self.res_output_shape = None\n","        self.final_activation = None\n","\n","        super(ResidualBlock, self).__init__(**kwargs)\n","\n","    def _build_layer(self, layer):\n","        \"\"\"Helper function for building layer\n","        Args:\n","            layer: Appends layer to internal layer list and builds it based on the current output\n","                   shape of ResidualBlocK. Updates current output shape.\n","        \"\"\"\n","        self.layers.append(layer)\n","        self.layers[-1].build(self.res_output_shape)\n","        self.res_output_shape = self.layers[-1].compute_output_shape(self.res_output_shape)\n","\n","    def build(self, input_shape):\n","\n","        with K.name_scope(self.name):  # name scope used to make sure weights get unique names\n","            self.layers = []\n","            self.res_output_shape = input_shape\n","\n","            for k in range(2):  # dilated conv block.\n","                name = 'conv1D_{}'.format(k)\n","                with K.name_scope(name):  # name scope used to make sure weights get unique names\n","                    conv = Conv1D(\n","                        filters=self.nb_filters,\n","                        kernel_size=self.kernel_size,\n","                        dilation_rate=self.dilation_rate,\n","                        padding=self.padding,\n","                        name=name,\n","                        kernel_initializer=self.kernel_initializer\n","                    )\n","                    if self.use_weight_norm:\n","                        from tensorflow_addons.layers import WeightNormalization\n","                        # wrap it. WeightNormalization API is different than BatchNormalization or LayerNormalization.\n","                        with K.name_scope('norm_{}'.format(k)):\n","                            conv = WeightNormalization(conv)\n","                    self._build_layer(conv)\n","\n","                with K.name_scope('norm_{}'.format(k)):\n","                    if self.use_batch_norm:\n","                        self._build_layer(BatchNormalization())\n","                    elif self.use_layer_norm:\n","                        self._build_layer(LayerNormalization())\n","                    elif self.use_weight_norm:\n","                        pass  # done above.\n","\n","                with K.name_scope('act_and_dropout_{}'.format(k)):\n","                    self._build_layer(Activation(self.activation, name='Act_Conv1D_{}'.format(k)))\n","                    self._build_layer(SpatialDropout1D(rate=self.dropout_rate, name='SDropout_{}'.format(k)))\n","\n","            if self.nb_filters != input_shape[-1]:\n","                # 1x1 conv to match the shapes (channel dimension).\n","                name = 'matching_conv1D'\n","                with K.name_scope(name):\n","                    # make and build this layer separately because it directly uses input_shape.\n","                    # 1x1 conv.\n","                    self.shape_match_conv = Conv1D(\n","                        filters=self.nb_filters,\n","                        kernel_size=1,\n","                        padding='same',\n","                        name=name,\n","                        kernel_initializer=self.kernel_initializer\n","                    )\n","            else:\n","                name = 'matching_identity'\n","                self.shape_match_conv = Lambda(lambda x: x, name=name)\n","\n","            with K.name_scope(name):\n","                self.shape_match_conv.build(input_shape)\n","                self.res_output_shape = self.shape_match_conv.compute_output_shape(input_shape)\n","\n","            self._build_layer(Activation(self.activation, name='Act_Conv_Blocks'))\n","            self.final_activation = Activation(self.activation, name='Act_Res_Block')\n","            self.final_activation.build(self.res_output_shape)  # probably isn't necessary\n","\n","            # this is done to force Keras to add the layers in the list to self._layers\n","            for layer in self.layers:\n","                self.__setattr__(layer.name, layer)\n","            self.__setattr__(self.shape_match_conv.name, self.shape_match_conv)\n","            self.__setattr__(self.final_activation.name, self.final_activation)\n","\n","            super(ResidualBlock, self).build(input_shape)  # done to make sure self.built is set True\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        \"\"\"\n","        Returns: A tuple where the first element is the residual model tensor, and the second\n","                 is the skip connection tensor.\n","        \"\"\"\n","        # https://arxiv.org/pdf/1803.01271.pdf  page 4, Figure 1 (b).\n","        # x1: Dilated Conv -> Norm -> Dropout (x2).\n","        # x2: Residual (1x1 matching conv - optional).\n","        # Output: x1 + x2.\n","        # x1 -> connected to skip connections.\n","        # x1 + x2 -> connected to the next block.\n","        #       input\n","        #     x1      x2\n","        #   conv1D    1x1 Conv1D (optional)\n","        #    ...\n","        #   conv1D\n","        #    ...\n","        #       x1 + x2\n","        x1 = inputs\n","        for layer in self.layers:\n","            training_flag = 'training' in dict(inspect.signature(layer.call).parameters)\n","            x1 = layer(x1, training=training) if training_flag else layer(x1)\n","        x1 = SE_Block(reduction=16)(x1)\n","\n","        # print('x1.shape = ',x1.shape)\n","        x2 = self.shape_match_conv(inputs)\n","        x1_x2 = self.final_activation(layers.add([x2, x1], name='Add_Res'))\n","        return [x1_x2, x1]\n","\n","    def compute_output_shape(self, input_shape):\n","        return [self.res_output_shape, self.res_output_shape]\n","\n","\n","class TCN(Layer):\n","    \"\"\"Creates a TCN layer.\n","        Input shape:\n","            A tensor of shape (batch_size, timesteps, input_dim).\n","        Args:\n","            nb_filters: The number of filters to use in the convolutional layers. Can be a list.\n","            kernel_size: The size of the kernel to use in each convolutional layer.\n","            dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n","            nb_stacks : The number of stacks of residual blocks to use.\n","            padding: The padding to use in the convolutional layers, 'causal' or 'same'.\n","            use_skip_connections: Boolean. If we want to add skip connections from input to each residual blocK.\n","            return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n","            activation: The activation used in the residual blocks o = Activation(x + F(x)).\n","            dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n","            kernel_initializer: Initializer for the kernel weights matrix (Conv1D).\n","            use_batch_norm: Whether to use batch normalization in the residual layers or not.\n","            use_layer_norm: Whether to use layer normalization in the residual layers or not.\n","            use_weight_norm: Whether to use weight normalization in the residual layers or not.\n","            kwargs: Any other arguments for configuring parent class Layer. For example \"name=str\", Name of the model.\n","                    Use unique names when using multiple TCN.\n","        Returns:\n","            A TCN layer.\n","        \"\"\"\n","\n","    def __init__(self,\n","                 nb_filters=64,\n","                 kernel_size=3,\n","                 nb_stacks=1,\n","                 dilations=(1, 2, 4, 8, 16, 32),\n","                 padding='causal',\n","                 use_skip_connections=True,\n","                 dropout_rate=0.0,\n","                 return_sequences=False,\n","                 activation='relu',\n","                 kernel_initializer='he_normal',\n","                 use_batch_norm=False,\n","                 use_layer_norm=False,\n","                 use_weight_norm=False,\n","                 **kwargs):\n","\n","        self.return_sequences = return_sequences\n","        self.dropout_rate = dropout_rate\n","        self.use_skip_connections = use_skip_connections\n","        self.dilations = dilations\n","        self.nb_stacks = nb_stacks\n","        self.kernel_size = kernel_size\n","        self.nb_filters = nb_filters\n","        self.activation = activation\n","        self.padding = padding\n","        self.kernel_initializer = kernel_initializer\n","        self.use_batch_norm = use_batch_norm\n","        self.use_layer_norm = use_layer_norm\n","        self.use_weight_norm = use_weight_norm\n","        self.skip_connections = []\n","        self.residual_blocks = []\n","        self.layers_outputs = []\n","        self.build_output_shape = None\n","        self.slicer_layer = None  # in case return_sequence=False\n","        self.output_slice_index = None  # in case return_sequence=False\n","        self.padding_same_and_time_dim_unknown = False  # edge case if padding='same' and time_dim = None\n","\n","        if self.use_batch_norm + self.use_layer_norm + self.use_weight_norm > 1:\n","            raise ValueError('Only one normalization can be specified at once.')\n","\n","        if isinstance(self.nb_filters, list):\n","            assert len(self.nb_filters) == len(self.dilations)\n","            if len(set(self.nb_filters)) > 1 and self.use_skip_connections:\n","                raise ValueError('Skip connections are not compatible '\n","                                 'with a list of filters, unless they are all equal.')\n","\n","        if padding != 'causal' and padding != 'same':\n","            raise ValueError(\"Only 'causal' or 'same' padding are compatible for this layer.\")\n","\n","        # initialize parent class\n","        super(TCN, self).__init__(**kwargs)\n","\n","    @property\n","    def receptive_field(self):\n","        return 1 + 2 * (self.kernel_size - 1) * self.nb_stacks * sum(self.dilations)\n","\n","    def build(self, input_shape):\n","\n","        # member to hold current output shape of the layer for building purposes\n","        self.build_output_shape = input_shape\n","\n","        # list to hold all the member ResidualBlocks\n","        self.residual_blocks = []\n","        total_num_blocks = self.nb_stacks * len(self.dilations)\n","        if not self.use_skip_connections:\n","            total_num_blocks += 1  # cheap way to do a false case for below\n","\n","        for s in range(self.nb_stacks):\n","            for i, d in enumerate(self.dilations):\n","                res_block_filters = self.nb_filters[i] if isinstance(self.nb_filters, list) else self.nb_filters\n","                self.residual_blocks.append(ResidualBlock(dilation_rate=d,\n","                                                          nb_filters=res_block_filters,\n","                                                          kernel_size=self.kernel_size,\n","                                                          padding=self.padding,\n","                                                          activation=self.activation,\n","                                                          dropout_rate=self.dropout_rate,\n","                                                          use_batch_norm=self.use_batch_norm,\n","                                                          use_layer_norm=self.use_layer_norm,\n","                                                          use_weight_norm=self.use_weight_norm,\n","                                                          kernel_initializer=self.kernel_initializer,\n","                                                          name='residual_block_{}'.format(len(self.residual_blocks))))\n","                # build newest residual block\n","                self.residual_blocks[-1].build(self.build_output_shape)\n","                self.build_output_shape = self.residual_blocks[-1].res_output_shape\n","\n","        # this is done to force keras to add the layers in the list to self._layers\n","        for layer in self.residual_blocks:\n","            self.__setattr__(layer.name, layer)\n","\n","        self.output_slice_index = None\n","        if self.padding == 'same':\n","            time = self.build_output_shape.as_list()[1]\n","            if time is not None:  # if time dimension is defined. e.g. shape = (bs, 500, input_dim).\n","                self.output_slice_index = int(self.build_output_shape.as_list()[1] / 2)\n","            else:\n","                # It will known at call time. c.f. self.call.\n","                self.padding_same_and_time_dim_unknown = True\n","\n","        else:\n","            self.output_slice_index = -1  # causal case.\n","        self.slicer_layer = Lambda(lambda tt: tt[:, self.output_slice_index, :], name='Slice_Output')\n","        self.slicer_layer.build(self.build_output_shape.as_list())\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\"\n","        Overridden in case keras uses it somewhere... no idea. Just trying to avoid future errors.\n","        \"\"\"\n","        if not self.built:\n","            self.build(input_shape)\n","        if not self.return_sequences:\n","            batch_size = self.build_output_shape[0]\n","            batch_size = batch_size.value if hasattr(batch_size, 'value') else batch_size\n","            nb_filters = self.build_output_shape[-1]\n","            return [batch_size, nb_filters]\n","        else:\n","            # Compatibility tensorflow 1.x\n","            return [v.value if hasattr(v, 'value') else v for v in self.build_output_shape]\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        x = inputs\n","        self.layers_outputs = [x]\n","        self.skip_connections = []\n","        for res_block in self.residual_blocks:\n","            try:\n","                x, skip_out = res_block(x, training=training)\n","            except TypeError:  # compatibility with tensorflow 1.x\n","                x, skip_out = res_block(K.cast(x, 'float32'), training=training)\n","            self.skip_connections.append(skip_out)\n","            self.layers_outputs.append(x)\n","\n","        if self.use_skip_connections:\n","            x = layers.add(self.skip_connections, name='Add_Skip_Connections')\n","            self.layers_outputs.append(x)\n","\n","        if not self.return_sequences:\n","            # case: time dimension is unknown. e.g. (bs, None, input_dim).\n","            if self.padding_same_and_time_dim_unknown:\n","                self.output_slice_index = K.shape(self.layers_outputs[-1])[1] // 2\n","            x = self.slicer_layer(x)\n","            self.layers_outputs.append(x)\n","        return x\n","\n","    def get_config(self):\n","        \"\"\"\n","        Returns the config of a the layer. This is used for saving and loading from a model\n","        :return: python dictionary with specs to rebuild layer\n","        \"\"\"\n","        config = super(TCN, self).get_config()\n","        config['nb_filters'] = self.nb_filters\n","        config['kernel_size'] = self.kernel_size\n","        config['nb_stacks'] = self.nb_stacks\n","        config['dilations'] = self.dilations\n","        config['padding'] = self.padding\n","        config['use_skip_connections'] = self.use_skip_connections\n","        config['dropout_rate'] = self.dropout_rate\n","        config['return_sequences'] = self.return_sequences\n","        config['activation'] = self.activation\n","        config['use_batch_norm'] = self.use_batch_norm\n","        config['use_layer_norm'] = self.use_layer_norm\n","        config['use_weight_norm'] = self.use_weight_norm\n","        config['kernel_initializer'] = self.kernel_initializer\n","        return config"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"AOrsJQO1k4Zp"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def compiled_tcn(num_feat,  # type: int\n","                 num_classes,  # type: int\n","                 nb_filters,  # type: int\n","                 kernel_size,  # type: int\n","                 dilations,  # type: List[int]\n","                 nb_stacks,  # type: int\n","                 max_len,  # type: int\n","                 output_len=1,  # type: int\n","                 padding='causal',  # type: str\n","                 use_skip_connections=False,  # type: bool\n","                 return_sequences=True,\n","                 regression=False,  # type: bool\n","                 dropout_rate=0.05,  # type: float\n","                 name='tcn',  # type: str,\n","                 kernel_initializer='he_normal',  # type: str,\n","                 activation='relu',  # type:str,\n","                 opt='adam',\n","                 learning_rate=0.002,\n","                 use_batch_norm=False,\n","                 use_layer_norm=False,\n","                 use_weight_norm=False):\n","    # type: (...) -> Model\n","    \"\"\"Creates a compiled TCN model for a given task (i.e. regression or classification).\n","    Classification uses a sparse categorical loss. Please input class ids and not one-hot encodings.\n","    Args:\n","        num_feat: The number of features of your input, i.e. the last dimension of: (batch_size, timesteps, input_dim).\n","        num_classes: The size of the final dense layer, how many classes we are predicting.\n","        nb_filters: The number of filters to use in the convolutional layers.\n","        kernel_size: The size of the kernel to use in each convolutional layer.\n","        dilations: The list of the dilations. Example is: [1, 2, 4, 8, 16, 32, 64].\n","        nb_stacks : The number of stacks of residual blocks to use.\n","        max_len: The maximum sequence length, use None if the sequence length is dynamic.\n","        padding: The padding to use in the convolutional layers.\n","        use_skip_connections: Boolean. If we want to add skip connections from input to each residual blocK.\n","        return_sequences: Boolean. Whether to return the last output in the output sequence, or the full sequence.\n","        regression: Whether the output should be continuous or discrete.\n","        dropout_rate: Float between 0 and 1. Fraction of the input units to drop.\n","        activation: The activation used in the residual blocks o = Activation(x + F(x)).\n","        name: Name of the model. Useful when having multiple TCN.\n","        kernel_initializer: Initializer for the kernel weights matrix (Conv1D).\n","        opt: Optimizer name.\n","        lr: Learning rate.\n","        use_batch_norm: Whether to use batch normalization in the residual layers or not.\n","        use_layer_norm: Whether to use layer normalization in the residual layers or not.\n","        use_weight_norm: Whether to use weight normalization in the residual layers or not.\n","    Returns:\n","        A compiled keras TCN.\n","    \"\"\"\n","\n","\n","    dilations = adjust_dilations(dilations)\n","\n","    input_layer = Input(shape=(max_len, num_feat))\n","\n","    x = TCN(nb_filters, kernel_size, nb_stacks, dilations, padding,\n","            use_skip_connections, dropout_rate, return_sequences,\n","            activation, kernel_initializer, use_batch_norm, use_layer_norm,\n","            use_weight_norm, name=name)(input_layer)\n","\n","    print('x.shape=', x.shape)\n","\n","    def get_opt():\n","        if opt == 'adam':\n","            return optimizers.Adam(learning_rate=learning_rate, clipnorm=1.)\n","        elif opt == 'rmsprop':\n","            return optimizers.RMSprop(learning_rate=learning_rate, clipnorm=1.)\n","        else:\n","            raise Exception('Only Adam and RMSProp are available here')\n","\n","    if not regression:\n","        # classification\n","        x = Dense(num_classes)(x)\n","        x = Activation('softmax')(x)\n","        output_layer = x\n","        model = Model(input_layer, output_layer)\n","\n","        # https://github.com/keras-team/keras/pull/11373\n","        # It's now in Keras@master but still not available with pip.\n","        # TODO remove later.\n","        def accuracy(y_true, y_pred):\n","            # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n","            if K.ndim(y_true) == K.ndim(y_pred):\n","                y_true = K.squeeze(y_true, -1)\n","            # convert dense predictions to labels\n","            y_pred_labels = K.argmax(y_pred, axis=-1)\n","            y_pred_labels = K.cast(y_pred_labels, K.floatx())\n","            return K.cast(K.equal(y_true, y_pred_labels), K.floatx())\n","\n","        model.compile(get_opt(), loss='categorical_crossentropy', metrics=[\"accuracy\"]) # sparse_categorical_crossentropy [1] [2]\n","    else:\n","        # regression\n","        x = Dense(output_len)(x)\n","        x = Activation('linear')(x)\n","        output_layer = x\n","        model = Model(input_layer, output_layer)\n","        model.compile(get_opt(), loss='mean_squared_error', metrics=[\"accuracy\"])\n","    print('model.x = {}'.format(input_layer.shape))\n","    print('model.y = {}'.format(output_layer.shape))\n","    return model\n","\n","\n","def tcn_full_summary(model: Model, expand_residual_blocks=True):\n","    import tensorflow as tf\n","    # 2.6.0-rc1, 2.5.0...\n","    versions = [int(v) for v in tf.__version__.split('-')[0].split('.')]\n","    if versions[0] <= 2 and versions[1] < 5:\n","        layers = model._layers.copy()  # store existing layers\n","        model._layers.clear()  # clear layers\n","\n","        for i in range(len(layers)):\n","            if isinstance(layers[i], TCN):\n","                for layer in layers[i]._layers:\n","                    if not isinstance(layer, ResidualBlock):\n","                        if not hasattr(layer, '__iter__'):\n","                            model._layers.append(layer)\n","                    else:\n","                        if expand_residual_blocks:\n","                            for lyr in layer._layers:\n","                                if not hasattr(lyr, '__iter__'):\n","                                    model._layers.append(lyr)\n","                        else:\n","                            model._layers.append(layer)\n","            else:\n","                model._layers.append(layers[i])\n","\n","        model.summary()  # print summary\n","\n","        # restore original layers\n","        model._layers.clear()\n","        [model._layers.append(lyr) for lyr in layers]\n","    else:\n","        print('WARNING: tcn_full_summary: Compatible with tensorflow 2.5.0 or below.')\n","        print('Use tensorboard instead. Example in keras-tcn/tasks/tcn_tensorboard.py.')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"nfg1LkiLk4Zv"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["# Dataset\n","from keras.utils.np_utils import to_categorical\n","from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n","import numpy\n","import plotly.graph_objects as go\n","import tensorflow\n","\n","\n","\n","class Gear_Dataset:\n","    def __init__(self,\n","                 filepath = 'C:/Users/user/Desktop/TCN/資料擷取/資料擷取_npy/mid',\n","                 series_length = 10240,\n","                 scale_method = None,\n","                 shuffle = True,\n","                 random_seed = None,\n","                 ):\n","\n","        self.filepath = filepath\n","        self.series_length = series_length\n","        self.scale_method = scale_method\n","        self.train_data = None\n","        self.label_data = None\n","        self.classification_dataset = None\n","        self.regression_dataset = None\n","        self.shuffle = shuffle\n","        self.random_seed = random_seed\n","\n","        self.__get_dataset()\n","\n","    @staticmethod\n","    def __scale_data(data, scale_method = None, verbose = False):\n","        scaler = scale_method\n","        series = scaler.fit_transform(data)\n","        if verbose:\n","            line = go.Scatter(y = data[:, 0][:10240], name = \"original\")\n","            scale_line = go.Scatter(y = series[:, 0][:10240], name = \"scale line\")\n","            go.Figure([line, scale_line]).show()\n","        return series\n","\n","    @staticmethod\n","    def __get_data_number(datas):\n","        data_shape = []\n","        for data in datas:\n","            data_shape.append(data.shape[0])\n","        return data_shape\n","\n","    @staticmethod\n","    def __create_label(label_shape_list):\n","        label_list = []\n","        for label_num in range(len(label_shape_list)):\n","            for _ in range(label_shape_list[label_num]):\n","                label_list.append(label_num)\n","\n","        return to_categorical(label_list, len(label_shape_list))\n","\n","    def __load_data(self, filepath, scale_method = None):\n","        GOOD = numpy.load(f'{filepath}/Good.npy')\n","        BC = numpy.load(f'{filepath}/BC.npy')\n","        LOOSE = numpy.load(f'{filepath}/Loose.npy')\n","        SHAFT = numpy.load(f'{filepath}/Shaft.npy')\n","        TOOTH_BREAK = numpy.load(f'{filepath}/Tooth Break.npy')\n","        WEAR = numpy.load(f'{filepath}/Wear.npy')\n","        datas_list = [GOOD, BC, LOOSE, SHAFT, TOOTH_BREAK, WEAR]\n","        if scale_method is not None:\n","            scale_datas_list = []\n","            for data in datas_list:\n","                scale_datas_list.append(self.__scale_data(data, scale_method=scale_method, verbose=False))\n","            return scale_datas_list\n","\n","        return datas_list\n","\n","    def __get_gear_data(self, filepath, series_length = 10240, scale_method = None):\n","        all_data = self.__load_data(filepath, scale_method)\n","        reshape_data = []\n","        for data in all_data:\n","            reshape_data.append(data.reshape(-1, series_length, 3))\n","        gear_labels = self.__create_label(self.__get_data_number(reshape_data))\n","        gear_train = numpy.concatenate(reshape_data)\n","        return gear_train, gear_labels\n","\n","    def split_dataset(self, tf_dataset, split = 8):\n","        test_dataset = tf_dataset.enumerate().filter(lambda x,y: x%10== split).map(lambda x,y: y)\n","        val_dataset = tf_dataset.enumerate().filter(lambda x,y: x%10> split).map(lambda x,y: y)\n","        train_dataset = tf_dataset.enumerate().filter(lambda x,y: x%10< split).map(lambda x,y: y)\n","        return train_dataset, val_dataset, test_dataset\n","\n","    def __shuffle(self):\n","        if self.random_seed is not None:\n","            numpy.random.seed(self.random_seed)\n","        p = numpy.random.permutation(len(self.label_data))\n","        return p\n","\n","    def __get_dataset(self):\n","        self.train_data, self.label_data = self.__get_gear_data(filepath=self.filepath, series_length=self.series_length, scale_method=self.scale_method)\n","\n","        if self.shuffle:\n","            random_parameter = self.__shuffle()\n","            self.train_data = self.train_data[random_parameter]\n","            self.label_data = self.label_data[random_parameter]\n","\n","        self.classification_dataset = (self.train_data, self.label_data)\n","\n","        self.regression_dataset = (self.train_data, self.train_data)\n","\n","    def to_tf_dataset(self):\n","        self.classification_dataset = tensorflow.data.Dataset.from_tensor_slices(self.classification_dataset)\n","        self.regression_dataset = tensorflow.data.Dataset.from_tensor_slices(self.regression_dataset)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"06kgBp9Tk4Zw"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(7349, 10240, 1)\n","(7349, 6)\n"]}],"source":["dataset = Gear_Dataset(series_length=10240, scale_method = MinMaxScaler(feature_range=(-1, 1))) #scale_method = MinMaxScaler(feature_range=(0, 1))\n","train_data, label_data = dataset.classification_dataset\n","train_data = train_data[:,:,0].reshape(-1, 10240,1)\n","print(train_data.shape)\n","print(label_data.shape)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"u4nqZ07yk4Zx","outputId":"25e5fcd8-ca39-41bc-dc44-cea4b9d17b8f"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["x.shape= (None, 32)\n","model.x = (None, None, 1)\n","model.y = (None, 6)\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None, 1)]         0         \n","                                                                 \n"," tcn (TCN)                   (None, 32)                109056    \n","                                                                 \n"," dense (Dense)               (None, 6)                 198       \n","                                                                 \n"," activation (Activation)     (None, 6)                 0         \n","                                                                 \n","=================================================================\n","Total params: 109,254\n","Trainable params: 108,358\n","Non-trainable params: 896\n","_________________________________________________________________\n"]}],"source":["model = compiled_tcn(return_sequences=False,\n","                     num_feat=1,\n","                     num_classes=6,\n","                     nb_filters=2,\n","                     kernel_size=8,\n","                     dilations=[2 ** i for i in range(2)],\n","                     nb_stacks=1,\n","                     activation='tanh',\n","                     # learning_rate=1e-4,\n","                     max_len=None,\n","                     use_batch_norm=True,\n","                     use_weight_norm=False,\n","                     use_layer_norm=False,\n","                     use_skip_connections=True)\n","model.summary()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"V_IsNssXk4Zy","outputId":"5ca16336-7a97-4d3d-cde0-277f3e770a86"}},{"cell_type":"code","execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\user\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["184/184 [==============================] - 69s 359ms/step - loss: 0.5282 - accuracy: 0.7915 - val_loss: 3.2786 - val_accuracy: 0.3014\n","Epoch 2/100\n","184/184 [==============================] - 66s 360ms/step - loss: 0.0990 - accuracy: 0.9709 - val_loss: 1.0311 - val_accuracy: 0.7231\n","Epoch 3/100\n","184/184 [==============================] - 67s 362ms/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.7269 - val_accuracy: 0.7408\n","Epoch 4/100\n","184/184 [==============================] - 67s 364ms/step - loss: 0.0772 - accuracy: 0.9777 - val_loss: 0.0556 - val_accuracy: 0.9762\n","Epoch 5/100\n","184/184 [==============================] - 67s 365ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 0.1914 - val_accuracy: 0.9061\n","Epoch 6/100\n","184/184 [==============================] - 66s 360ms/step - loss: 0.0311 - accuracy: 0.9913 - val_loss: 0.0495 - val_accuracy: 0.9844\n","Epoch 7/100\n","184/184 [==============================] - 66s 361ms/step - loss: 0.0350 - accuracy: 0.9893 - val_loss: 0.0447 - val_accuracy: 0.9823\n","Epoch 8/100\n","184/184 [==============================] - 69s 372ms/step - loss: 0.0322 - accuracy: 0.9905 - val_loss: 0.0405 - val_accuracy: 0.9898\n","Epoch 9/100\n","184/184 [==============================] - 70s 379ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.2233 - val_accuracy: 0.9088\n","Epoch 10/100\n","184/184 [==============================] - 68s 367ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.0037 - val_accuracy: 0.9993\n","Epoch 11/100\n","184/184 [==============================] - 67s 364ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.1327 - val_accuracy: 0.9503\n","Epoch 12/100\n","184/184 [==============================] - 66s 356ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 5.9008e-04 - val_accuracy: 1.0000\n","Epoch 13/100\n","184/184 [==============================] - 66s 357ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0631 - val_accuracy: 0.9755\n","Epoch 14/100\n","184/184 [==============================] - 65s 355ms/step - loss: 0.0213 - accuracy: 0.9927 - val_loss: 0.1667 - val_accuracy: 0.9449\n","Epoch 15/100\n","184/184 [==============================] - 65s 353ms/step - loss: 0.0149 - accuracy: 0.9947 - val_loss: 0.1306 - val_accuracy: 0.9599\n","Epoch 16/100\n","184/184 [==============================] - 65s 353ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 1.9310e-04 - val_accuracy: 1.0000\n","Epoch 17/100\n","184/184 [==============================] - 66s 359ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0011 - val_accuracy: 1.0000\n","Epoch 18/100\n","184/184 [==============================] - 65s 353ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.0095 - val_accuracy: 0.9980\n","Epoch 19/100\n","184/184 [==============================] - 66s 356ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 3.4634e-04 - val_accuracy: 1.0000\n","Epoch 20/100\n","184/184 [==============================] - 66s 361ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 2.3123 - val_accuracy: 0.7980\n","Epoch 21/100\n","184/184 [==============================] - 66s 358ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.3731 - val_accuracy: 0.8925\n","Epoch 22/100\n","184/184 [==============================] - 66s 357ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 6.6931e-05 - val_accuracy: 1.0000\n","Epoch 23/100\n","184/184 [==============================] - 65s 356ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 3.9669e-04 - val_accuracy: 1.0000\n","Epoch 24/100\n","184/184 [==============================] - 68s 368ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.5232 - val_accuracy: 0.8660\n","Epoch 25/100\n","184/184 [==============================] - 67s 362ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 3.4685 - val_accuracy: 0.6599\n","Epoch 26/100\n","184/184 [==============================] - 67s 362ms/step - loss: 0.0162 - accuracy: 0.9940 - val_loss: 3.8416e-04 - val_accuracy: 1.0000\n","Epoch 27/100\n","105/184 [================>.............] - ETA: 27s - loss: 0.0503 - accuracy: 0.9848"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33328/2383655577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1019\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[1;34m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1008\u001b[0m             run_step, jit_compile=True, experimental_relax_shapes=True)\n\u001b[0;32m   1009\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m   1012\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m-> 1312\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2887\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2888\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2890\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3688\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3689\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1000\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1001\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    857\u001b[0m     \u001b[1;31m# Run forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m       \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m--> 451\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    452\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33328/2490970088.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, **kwargs)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mres_block\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresidual_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# compatibility with tensorflow 1.x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33328/2490970088.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[0mtraining_flag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'training'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtraining_flag\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSE_Block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1096\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_call_info_injected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\activation.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\activations.py\u001b[0m in \u001b[0;36mtanh\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    371\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msinh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcosh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m   \"\"\"\n\u001b[1;32m--> 373\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mtanh\u001b[1;34m(x, name)\u001b[0m\n\u001b[0;32m  11357\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11358\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11359\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m  11360\u001b[0m         _ctx, \"Tanh\", name, x)\n\u001b[0;32m  11361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = model.fit(x=train_data, y=label_data, batch_size=32, epochs=100, validation_split=0.2, shuffle=True)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IQpSNzkSk4Zz","outputId":"1f30d598-f695-416b-9061-dcde7f2b94ab"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["history.history"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"eQ5E6_-yk4Zz"}},{"cell_type":"code","execution_count":null,"outputs":[],"source":[""],"metadata":{"pycharm":{"name":"#%%\n"},"id":"tbqtRvtsk4Z0"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"name":"tcn_classification_1Channel.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}